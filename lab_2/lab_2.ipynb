{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:38:52.788608Z",
     "start_time": "2025-01-04T13:38:52.717946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np"
   ],
   "id": "8cf5ff1e0500e3b2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-04T13:38:52.797813Z",
     "start_time": "2025-01-04T13:38:52.789113Z"
    }
   },
   "source": [
    "# 1\n",
    "# Example dataset of gaming computers with their specifications\n",
    "gaming_computers = {\n",
    "    \"PC1\": {\"price\": 900, \"performance\": 85, \"power_consumption\": 65, \"screen_size\": 15.6, \"ram\": 8, \"storage\": 512},\n",
    "    \"PC2\": {\"price\": 1200, \"performance\": 95, \"power_consumption\": 75, \"screen_size\": 17.3, \"ram\": 16, \"storage\": 1024},\n",
    "    \"PC3\": {\"price\": 750, \"performance\": 80, \"power_consumption\": 55, \"screen_size\": 14, \"ram\": 8, \"storage\": 256},\n",
    "    \"PC4\": {\"price\": 1500, \"performance\": 110, \"power_consumption\": 85, \"screen_size\": 18, \"ram\": 32, \"storage\": 2048},\n",
    "    \"PC5\": {\"price\": 1100, \"performance\": 90, \"power_consumption\": 70, \"screen_size\": 16, \"ram\": 16, \"storage\": 1024},\n",
    "}\n",
    "\n",
    "# Weighting the importance of each attribute in gaming performance (for *Stalker 2* and similar games)\n",
    "weights = {\n",
    "    \"price\": 0.2,  # less important in gaming, but still a consideration\n",
    "    \"performance\": 0.4,  # main factor for gaming\n",
    "    \"power_consumption\": 0.1,  # energy efficiency is important, but secondary\n",
    "    \"screen_size\": 0.1,  # useful but not as crucial as other factors\n",
    "    \"ram\": 0.1,  # more RAM is good, but modern games also rely on CPU/GPU performance\n",
    "    \"storage\": 0.1,  # SSD storage can improve game load times, but isn't as important as performance\n",
    "}\n",
    "\n",
    "def normalize(data, method=\"range\"):\n",
    "    \"\"\"\n",
    "    Normalize the data using the specified method.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Raw data with computer configurations.\n",
    "        method (str): The normalization method. Options: \"range\", \"max\".\n",
    "\n",
    "    Returns:\n",
    "        dict: Normalized data.\n",
    "    \"\"\"\n",
    "    normalized = {}\n",
    "    \n",
    "    for indicator in data[next(iter(data))].keys():\n",
    "        values = [alt[indicator] for alt in data.values()]\n",
    "        min_val, max_val = min(values), max(values)\n",
    "        \n",
    "        for alt, metrics in data.items():\n",
    "            if method == \"range\":\n",
    "                norm_value = (metrics[indicator] - min_val) / (max_val - min_val)\n",
    "            elif method == \"max\":\n",
    "                norm_value = metrics[indicator] / max_val\n",
    "            \n",
    "            if alt not in normalized:\n",
    "                normalized[alt] = {}\n",
    "            normalized[alt][indicator] = norm_value\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def additive_aggregation(normalized_data, weights):\n",
    "    \"\"\"\n",
    "    Aggregate the normalized data using additive aggregation method.\n",
    "\n",
    "    Args:\n",
    "        normalized_data (dict): Normalized data.\n",
    "        weights (dict): Weights for each attribute.\n",
    "\n",
    "    Returns:\n",
    "        dict: Aggregated scores for each computer.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "    \n",
    "    for alt, metrics in normalized_data.items():\n",
    "        aggregated[alt] = sum(metrics[indicator] * weights[indicator] for indicator in metrics)\n",
    "        \n",
    "    return aggregated\n",
    "\n",
    "def multiplicative_aggregation(normalized_data, weights):\n",
    "    \"\"\"\n",
    "    Aggregate the normalized data using multiplicative aggregation method.\n",
    "\n",
    "    Args:\n",
    "        normalized_data (dict): Normalized data.\n",
    "        weights (dict): Weights for each attribute.\n",
    "\n",
    "    Returns:\n",
    "        dict: Aggregated scores for each computer.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "    \n",
    "    for alt, metrics in normalized_data.items():\n",
    "        aggregated[alt] = 1\n",
    "        for indicator in metrics:\n",
    "            aggregated[alt] *= metrics[indicator] ** weights[indicator]\n",
    "            \n",
    "    return aggregated\n",
    "\n",
    "# Main process to normalize and aggregate data with different methods\n",
    "def evaluate_computers(data, weights):\n",
    "    \"\"\"\n",
    "    Evaluate the computers based on different aggregation methods.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Raw data of computers.\n",
    "        weights (dict): Weights for each attribute.\n",
    "\n",
    "    Returns:\n",
    "        dict: Final aggregated scores for each method.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # Range normalization + Additive aggregation\n",
    "    normalized_data_range = normalize(data, method=\"range\")\n",
    "    results[\"Range + Additive\"] = additive_aggregation(normalized_data_range, weights)\n",
    "\n",
    "    # Range normalization + Multiplicative aggregation\n",
    "    results[\"Range + Multiplicative\"] = multiplicative_aggregation(normalized_data_range, weights)\n",
    "\n",
    "    # Max normalization + Additive aggregation\n",
    "    normalized_data_max = normalize(data, method=\"max\")\n",
    "    results[\"Max + Additive\"] = additive_aggregation(normalized_data_max, weights)\n",
    "\n",
    "    # Max normalization + Multiplicative aggregation\n",
    "    results[\"Max + Multiplicative\"] = multiplicative_aggregation(normalized_data_max, weights)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Evaluate the computers using the defined methods\n",
    "evaluation_results = evaluate_computers(gaming_computers, weights)\n",
    "\n",
    "# Displaying the results\n",
    "for method, result in evaluation_results.items():\n",
    "    print(f\"Results for {method}:\")\n",
    "    for computer, score in result.items():\n",
    "        print(f\"  {computer}: {score:.4f}\")\n",
    "    print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Range + Additive:\n",
      "  PC1: 0.1943\n",
      "  PC2: 0.5454\n",
      "  PC3: 0.0000\n",
      "  PC4: 1.0000\n",
      "  PC5: 0.4029\n",
      "\n",
      "Results for Range + Multiplicative:\n",
      "  PC1: 0.0000\n",
      "  PC2: 0.5306\n",
      "  PC3: 0.0000\n",
      "  PC4: 1.0000\n",
      "  PC5: 0.3965\n",
      "\n",
      "Results for Max + Additive:\n",
      "  PC1: 0.6422\n",
      "  PC2: 0.7898\n",
      "  PC3: 0.5709\n",
      "  PC4: 1.0000\n",
      "  PC5: 0.7452\n",
      "\n",
      "Results for Max + Multiplicative:\n",
      "  PC1: 0.5923\n",
      "  PC2: 0.7723\n",
      "  PC3: 0.5060\n",
      "  PC4: 1.0000\n",
      "  PC5: 0.7319\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T13:38:52.808328Z",
     "start_time": "2025-01-04T13:38:52.797813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2\n",
    "def sugeno_integral(criteria, weights, density):\n",
    "    \"\"\"\n",
    "    Calculates the Sugeno integral for a given set of criteria and weights.\n",
    "\n",
    "    Args:\n",
    "        criteria (list of float): The values of the criteria to aggregate.\n",
    "        weights (list of float): The importance of each criterion (weights).\n",
    "        density (function or list of float): A function or predefined density values to modify the aggregation process.\n",
    "\n",
    "    Returns:\n",
    "        float: The Sugeno integral aggregation result.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the density values do not match the length of the criteria list.\n",
    "    \"\"\"\n",
    "    # Sort the criteria and corresponding weights in descending order\n",
    "    sorted_indices = np.argsort(criteria)[::-1]\n",
    "    sorted_criteria = np.array(criteria)[sorted_indices]\n",
    "    sorted_weights = np.array(weights)[sorted_indices]\n",
    "\n",
    "    # Evaluate the density values\n",
    "    if callable(density):\n",
    "        density_values = [density(i + 1, len(criteria)) for i in range(len(criteria))]\n",
    "    else:\n",
    "        density_values = np.array(density)\n",
    "\n",
    "    # Check if density values match the number of criteria\n",
    "    if len(density_values) != len(criteria):\n",
    "        raise ValueError(\"The density measure must match the number of criteria.\")\n",
    "    \n",
    "    # Apply Sugeno integral aggregation: min(criterion, density) for each criterion, then max over all\n",
    "    sugeno_values = [min(sorted_criteria[i], density_values[i]) for i in range(len(criteria))]\n",
    "    \n",
    "    return max(sugeno_values)\n",
    "\n",
    "\n",
    "def normalize_data(raw_data):\n",
    "    \"\"\"\n",
    "    Normalizes the raw data for each criterion based on the maximum value.\n",
    "\n",
    "    Args:\n",
    "        raw_data (dict): A dictionary where keys are PC names and values are dictionaries of criteria and their values.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of normalized data for each PC.\n",
    "    \"\"\"\n",
    "    normalized_data = {}\n",
    "    \n",
    "    for key, values in raw_data.items():\n",
    "        normalized_data[key] = {\n",
    "            criterion: (1 / value if criterion == \"price\" else value / max([d[criterion] for d in raw_data.values()]))\n",
    "            for criterion, value in values.items()\n",
    "        }\n",
    "        \n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "# Example dataset of gaming computers with their specifications\n",
    "gaming_computers = {\n",
    "    \"PC1\": {\"price\": 900, \"performance\": 85, \"power_consumption\": 65, \"screen_size\": 15.6, \"ram\": 8, \"storage\": 512},\n",
    "    \"PC2\": {\"price\": 1200, \"performance\": 95, \"power_consumption\": 75, \"screen_size\": 17.3, \"ram\": 16, \"storage\": 1024},\n",
    "    \"PC3\": {\"price\": 750, \"performance\": 80, \"power_consumption\": 55, \"screen_size\": 14, \"ram\": 8, \"storage\": 256},\n",
    "    \"PC4\": {\"price\": 1500, \"performance\": 110, \"power_consumption\": 85, \"screen_size\": 18, \"ram\": 32, \"storage\": 2048},\n",
    "    \"PC5\": {\"price\": 1100, \"performance\": 90, \"power_consumption\": 70, \"screen_size\": 16, \"ram\": 16, \"storage\": 1024},\n",
    "}\n",
    "\n",
    "# Weighting the importance of each attribute in gaming performance (for *Stalker 2* and similar games)\n",
    "weights = {\n",
    "    \"price\": 0.2,\n",
    "    \"performance\": 0.4,\n",
    "    \"power_consumption\": 0.1,\n",
    "    \"screen_size\": 0.1,\n",
    "    \"ram\": 0.1,\n",
    "    \"storage\": 0.1,\n",
    "}\n",
    "\n",
    "# Normalize the data\n",
    "normalized_data = normalize_data(gaming_computers)\n",
    "\n",
    "# Modalities (density functions)\n",
    "modalities = {\n",
    "    \"possibility\": lambda i, n: 1,  # Maximum possibility, no change based on position\n",
    "    \"probability\": lambda i, n: i / n,  # Linearly increasing density based on rank\n",
    "    \"necessity\": lambda i, n: (n - i + 1) / n,  # Linearly decreasing density based on rank\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = {}\n",
    "\n",
    "# Compute Sugeno integral for each modality\n",
    "for modality, density_func in modalities.items():\n",
    "    results[modality] = {}\n",
    "    for pc, criteria_values in normalized_data.items():\n",
    "        criteria_list = list(criteria_values.values())\n",
    "        weight_list = list(weights.values())\n",
    "        results[modality][pc] = sugeno_integral(criteria_list, weight_list, density_func)\n",
    "\n",
    "# Display results\n",
    "for modality, scores in results.items():\n",
    "    print(f\"Results for modality '{modality}':\")\n",
    "    for pc, score in scores.items():\n",
    "        print(f\"  {pc}: {score}\")\n",
    "    print()"
   ],
   "id": "125ebdda5d229081",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for modality 'possibility':\n",
      "  PC1: 0.8666666666666667\n",
      "  PC2: 0.9611111111111111\n",
      "  PC3: 0.7777777777777778\n",
      "  PC4: 1.0\n",
      "  PC5: 0.8888888888888888\n",
      "\n",
      "Results for modality 'probability':\n",
      "  PC1: 0.5\n",
      "  PC2: 0.5\n",
      "  PC3: 0.5\n",
      "  PC4: 0.8333333333333334\n",
      "  PC5: 0.5\n",
      "\n",
      "Results for modality 'necessity':\n",
      "  PC1: 0.8666666666666667\n",
      "  PC2: 0.9611111111111111\n",
      "  PC3: 0.7777777777777778\n",
      "  PC4: 1.0\n",
      "  PC5: 0.8888888888888888\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
